{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pygithub in /home/markus2000/miniconda3/envs/data_mining/lib/python3.11/site-packages (2.4.0)\n",
      "Requirement already satisfied: pynacl>=1.4.0 in /home/markus2000/miniconda3/envs/data_mining/lib/python3.11/site-packages (from pygithub) (1.5.0)\n",
      "Requirement already satisfied: requests>=2.14.0 in /home/markus2000/miniconda3/envs/data_mining/lib/python3.11/site-packages (from pygithub) (2.32.3)\n",
      "Requirement already satisfied: pyjwt>=2.4.0 in /home/markus2000/miniconda3/envs/data_mining/lib/python3.11/site-packages (from pyjwt[crypto]>=2.4.0->pygithub) (2.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /home/markus2000/miniconda3/envs/data_mining/lib/python3.11/site-packages (from pygithub) (4.12.2)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /home/markus2000/miniconda3/envs/data_mining/lib/python3.11/site-packages (from pygithub) (2.2.3)\n",
      "Requirement already satisfied: Deprecated in /home/markus2000/miniconda3/envs/data_mining/lib/python3.11/site-packages (from pygithub) (1.2.14)\n",
      "Requirement already satisfied: cryptography>=3.4.0 in /home/markus2000/miniconda3/envs/data_mining/lib/python3.11/site-packages (from pyjwt[crypto]>=2.4.0->pygithub) (43.0.1)\n",
      "Requirement already satisfied: cffi>=1.4.1 in /home/markus2000/miniconda3/envs/data_mining/lib/python3.11/site-packages (from pynacl>=1.4.0->pygithub) (1.17.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/markus2000/miniconda3/envs/data_mining/lib/python3.11/site-packages (from requests>=2.14.0->pygithub) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/markus2000/miniconda3/envs/data_mining/lib/python3.11/site-packages (from requests>=2.14.0->pygithub) (3.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/markus2000/miniconda3/envs/data_mining/lib/python3.11/site-packages (from requests>=2.14.0->pygithub) (2024.8.30)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /home/markus2000/miniconda3/envs/data_mining/lib/python3.11/site-packages (from Deprecated->pygithub) (1.16.0)\n",
      "Requirement already satisfied: pycparser in /home/markus2000/miniconda3/envs/data_mining/lib/python3.11/site-packages (from cffi>=1.4.1->pynacl>=1.4.0->pygithub) (2.22)\n"
     ]
    }
   ],
   "source": [
    "!pip install pygithub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " --- Finished the fetching ---\n",
      "              repo_name                                     readme_content\n",
      "0           public-apis  # Try Public APIs for free\\nThe Public APIs re...\n",
      "1  system-design-primer  *[English](README.md) ∙ [日本語](README-ja.md) ∙ ...\n",
      "2        awesome-python  # Awesome Python [![Awesome](https://cdn.rawgi...\n",
      "3                Python  <div align=\"center\">\\n<!-- Title: -->\\n  <a hr...\n",
      "4               AutoGPT  # AutoGPT: Build, Deploy, and Run AI Agents\\n\\...\n"
     ]
    }
   ],
   "source": [
    "from github import Github as gt\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "g = gt(\"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\")\n",
    "\n",
    "# Search for repositories based on keywords, stars, etc.\n",
    "repositories = g.search_repositories(\n",
    "    query=\"language:python stars:>1000\", sort=\"stars\", order=\"desc\"\n",
    ")\n",
    "#Reduce dimensionality then find meaningfull clusters\n",
    "# list to save names and readme files\n",
    "repos_data = []\n",
    "\n",
    "# Loop through the repositories and fetch relevant data\n",
    "for repo in repositories[:1000]:  # Limit to top 100 repositories\n",
    "    # print(f\"Repository Name: {repo.name}\")\n",
    "    # print(f\"Owner: {repo.owner.login}\")\n",
    "    # print(f\"Stars: {repo.stargazers_count}\")\n",
    "    # print(f\"URL: {repo.html_url}\")\n",
    "    # print(\"-----\")\n",
    "\n",
    "    # Fetch and display the content of the README file\n",
    "    # Fetch and display the first 1000 characters of the README file, if available\n",
    "    try:\n",
    "        readme = repo.get_readme()  # Try to fetch the README file\n",
    "\n",
    "        if readme:  # If the README exists\n",
    "            try:\n",
    "                # Decode the content to a string\n",
    "                readme_content = readme.decoded_content.decode(\n",
    "                    \"utf-8\"\n",
    "                )  # important to include the UTF cuz i was getting weird results otherwise\n",
    "                readme_content = readme_content[:1000]\n",
    "\n",
    "                # Store the repo name and Readme file in a list\n",
    "                repos_data.append(\n",
    "                    {\"repo_name\": repo.name, \"readme_content\": readme_content}\n",
    "                )\n",
    "\n",
    "            except UnicodeDecodeError:\n",
    "                print(\"README exists, but couldn't be decoded as 'utf-8'.\")\n",
    "        else:\n",
    "            print(f\"No README found for repository {repo.name}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching README for repository {repo.name}: {e}\")\n",
    "\n",
    "\n",
    "print(\"\\n --- Finished the fetching ---\")\n",
    "\n",
    "repos_df = pd.DataFrame(repos_data)\n",
    "\n",
    "# We now have a dataframe that contains 2 columns, the repo name and the readme content\n",
    "\n",
    "print(repos_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from github import Github as gt\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "repos_df.to_csv('repos.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U -q google.generativeai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting genai\n",
      "  Downloading genai-2.1.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: ipython<9.0.0,>=8.10.0 in /home/markus2000/miniconda3/envs/data_mining/lib/python3.11/site-packages (from genai) (8.27.0)\n",
      "Collecting openai<0.28.0,>=0.27.0 (from genai)\n",
      "  Downloading openai-0.27.10-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting tabulate<0.10.0,>=0.9.0 (from genai)\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Collecting tiktoken<0.4.0,>=0.3.2 (from genai)\n",
      "  Downloading tiktoken-0.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: decorator in /home/markus2000/miniconda3/envs/data_mining/lib/python3.11/site-packages (from ipython<9.0.0,>=8.10.0->genai) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/markus2000/miniconda3/envs/data_mining/lib/python3.11/site-packages (from ipython<9.0.0,>=8.10.0->genai) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in /home/markus2000/miniconda3/envs/data_mining/lib/python3.11/site-packages (from ipython<9.0.0,>=8.10.0->genai) (0.1.7)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /home/markus2000/miniconda3/envs/data_mining/lib/python3.11/site-packages (from ipython<9.0.0,>=8.10.0->genai) (3.0.47)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/markus2000/miniconda3/envs/data_mining/lib/python3.11/site-packages (from ipython<9.0.0,>=8.10.0->genai) (2.18.0)\n",
      "Requirement already satisfied: stack-data in /home/markus2000/miniconda3/envs/data_mining/lib/python3.11/site-packages (from ipython<9.0.0,>=8.10.0->genai) (0.6.2)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in /home/markus2000/miniconda3/envs/data_mining/lib/python3.11/site-packages (from ipython<9.0.0,>=8.10.0->genai) (5.14.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6 in /home/markus2000/miniconda3/envs/data_mining/lib/python3.11/site-packages (from ipython<9.0.0,>=8.10.0->genai) (4.12.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/markus2000/miniconda3/envs/data_mining/lib/python3.11/site-packages (from ipython<9.0.0,>=8.10.0->genai) (4.8.0)\n",
      "Requirement already satisfied: requests>=2.20 in /home/markus2000/miniconda3/envs/data_mining/lib/python3.11/site-packages (from openai<0.28.0,>=0.27.0->genai) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /home/markus2000/miniconda3/envs/data_mining/lib/python3.11/site-packages (from openai<0.28.0,>=0.27.0->genai) (4.66.5)\n",
      "Collecting aiohttp (from openai<0.28.0,>=0.27.0->genai)\n",
      "  Downloading aiohttp-3.10.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.6 kB)\n",
      "Collecting regex>=2022.1.18 (from tiktoken<0.4.0,>=0.3.2->genai)\n",
      "  Downloading regex-2024.9.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /home/markus2000/miniconda3/envs/data_mining/lib/python3.11/site-packages (from jedi>=0.16->ipython<9.0.0,>=8.10.0->genai) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/markus2000/miniconda3/envs/data_mining/lib/python3.11/site-packages (from pexpect>4.3->ipython<9.0.0,>=8.10.0->genai) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/markus2000/miniconda3/envs/data_mining/lib/python3.11/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython<9.0.0,>=8.10.0->genai) (0.2.13)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/markus2000/miniconda3/envs/data_mining/lib/python3.11/site-packages (from requests>=2.20->openai<0.28.0,>=0.27.0->genai) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/markus2000/miniconda3/envs/data_mining/lib/python3.11/site-packages (from requests>=2.20->openai<0.28.0,>=0.27.0->genai) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/markus2000/miniconda3/envs/data_mining/lib/python3.11/site-packages (from requests>=2.20->openai<0.28.0,>=0.27.0->genai) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/markus2000/miniconda3/envs/data_mining/lib/python3.11/site-packages (from requests>=2.20->openai<0.28.0,>=0.27.0->genai) (2024.8.30)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->openai<0.28.0,>=0.27.0->genai)\n",
      "  Downloading aiohappyeyeballs-2.4.0-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->openai<0.28.0,>=0.27.0->genai)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/markus2000/miniconda3/envs/data_mining/lib/python3.11/site-packages (from aiohttp->openai<0.28.0,>=0.27.0->genai) (23.1.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->openai<0.28.0,>=0.27.0->genai)\n",
      "  Downloading frozenlist-1.4.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->openai<0.28.0,>=0.27.0->genai)\n",
      "  Downloading multidict-6.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
      "Collecting yarl<2.0,>=1.12.0 (from aiohttp->openai<0.28.0,>=0.27.0->genai)\n",
      "  Downloading yarl-1.12.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (49 kB)\n",
      "Requirement already satisfied: executing>=1.2.0 in /home/markus2000/miniconda3/envs/data_mining/lib/python3.11/site-packages (from stack-data->ipython<9.0.0,>=8.10.0->genai) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /home/markus2000/miniconda3/envs/data_mining/lib/python3.11/site-packages (from stack-data->ipython<9.0.0,>=8.10.0->genai) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /home/markus2000/miniconda3/envs/data_mining/lib/python3.11/site-packages (from stack-data->ipython<9.0.0,>=8.10.0->genai) (0.2.3)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/markus2000/miniconda3/envs/data_mining/lib/python3.11/site-packages (from asttokens>=2.1.0->stack-data->ipython<9.0.0,>=8.10.0->genai) (1.16.0)\n",
      "Downloading genai-2.1.0-py3-none-any.whl (16 kB)\n",
      "Downloading openai-0.27.10-py3-none-any.whl (76 kB)\n",
      "Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Downloading tiktoken-0.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.9.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (792 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m792.8/792.8 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.10.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiohappyeyeballs-2.4.0-py3-none-any.whl (12 kB)\n",
      "Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading frozenlist-1.4.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (272 kB)\n",
      "Downloading multidict-6.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
      "Downloading yarl-1.12.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (487 kB)\n",
      "Installing collected packages: tabulate, regex, multidict, frozenlist, aiohappyeyeballs, yarl, tiktoken, aiosignal, aiohttp, openai, genai\n",
      "Successfully installed aiohappyeyeballs-2.4.0 aiohttp-3.10.6 aiosignal-1.3.1 frozenlist-1.4.1 genai-2.1.0 multidict-6.1.0 openai-0.27.10 regex-2024.9.11 tabulate-0.9.0 tiktoken-0.3.3 yarl-1.12.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/markus2000/miniconda3/envs/data_mining/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import google.generativeai as genai\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyDi3TiYc1vLv8GO7AT5RKWNT83tmSKSAS4\"\n",
    "\n",
    "genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [05:03<00:00,  3.30it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "repos_df = pd.read_csv('repos.csv')\n",
    "tqdm.pandas()\n",
    "\n",
    "from google.api_core import retry\n",
    "\n",
    "\n",
    "def make_embed_text_fn(model):\n",
    "\n",
    "  @retry.Retry(timeout=300.0)\n",
    "  def embed_fn(text: str) -> list[float]:\n",
    "    # Set the task_type to CLUSTERING.\n",
    "    embedding = genai.embed_content(model=model,\n",
    "                                    content=text,\n",
    "                                    task_type=\"clustering\")\n",
    "    return embedding[\"embedding\"]\n",
    "\n",
    "  return embed_fn\n",
    "\n",
    "def create_embeddings(df):\n",
    "  model = 'models/embedding-001'\n",
    "  df['Embeddings'] = df['readme_content'].progress_apply(make_embed_text_fn(model))\n",
    "  return df\n",
    "\n",
    "df_train = create_embeddings(repos_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_clusters=2, The Davies Bouldin Score is 4.748033366364937, The Silhouette Score is 0.03920383378863335\n",
      "For n_clusters=3, The Davies Bouldin Score is 4.700835884369609, The Silhouette Score is 0.021645518019795418\n",
      "For n_clusters=4, The Davies Bouldin Score is 4.972869843684901, The Silhouette Score is 0.021018855273723602\n",
      "For n_clusters=5, The Davies Bouldin Score is 5.067001838436529, The Silhouette Score is 0.021590938791632652\n",
      "For n_clusters=6, The Davies Bouldin Score is 5.203309065749335, The Silhouette Score is 0.0203187745064497\n",
      "For n_clusters=7, The Davies Bouldin Score is 5.113009797446037, The Silhouette Score is 0.018445223569869995\n",
      "For n_clusters=8, The Davies Bouldin Score is 5.035525292464658, The Silhouette Score is 0.014140766113996506\n",
      "For n_clusters=9, The Davies Bouldin Score is 5.094993243809416, The Silhouette Score is 0.011068868450820446\n",
      "For n_clusters=10, The Davies Bouldin Score is 5.1355250803478665, The Silhouette Score is 0.012406100519001484\n",
      "For n_clusters=11, The Davies Bouldin Score is 4.886044920604228, The Silhouette Score is 0.012966558337211609\n",
      "For n_clusters=12, The Davies Bouldin Score is 4.87451816749483, The Silhouette Score is 0.012052757665514946\n",
      "For n_clusters=13, The Davies Bouldin Score is 4.900192419818371, The Silhouette Score is 0.01538220327347517\n",
      "For n_clusters=14, The Davies Bouldin Score is 4.762731584823672, The Silhouette Score is 0.014356788247823715\n",
      "For n_clusters=15, The Davies Bouldin Score is 4.687713822378109, The Silhouette Score is 0.015025383792817593\n",
      "For n_clusters=16, The Davies Bouldin Score is 4.617236530595891, The Silhouette Score is 0.014623590745031834\n",
      "For n_clusters=17, The Davies Bouldin Score is 4.625163635388336, The Silhouette Score is 0.014468076638877392\n",
      "For n_clusters=18, The Davies Bouldin Score is 4.729023955567301, The Silhouette Score is 0.009635906666517258\n",
      "For n_clusters=19, The Davies Bouldin Score is 4.582825569935818, The Silhouette Score is 0.010026300325989723\n",
      "For n_clusters=20, The Davies Bouldin Score is 4.562474524826316, The Silhouette Score is 0.009062455967068672\n",
      "For n_clusters=21, The Davies Bouldin Score is 4.658472974251772, The Silhouette Score is 0.004570795223116875\n",
      "For n_clusters=22, The Davies Bouldin Score is 4.566069401566344, The Silhouette Score is 0.005456141661852598\n",
      "For n_clusters=23, The Davies Bouldin Score is 4.570400406857304, The Silhouette Score is 0.0062636323273181915\n",
      "For n_clusters=24, The Davies Bouldin Score is 4.54795058076641, The Silhouette Score is 0.004553548060357571\n",
      "For n_clusters=25, The Davies Bouldin Score is 4.512292330504121, The Silhouette Score is 0.0044397530145943165\n",
      "For n_clusters=26, The Davies Bouldin Score is 4.442737591668955, The Silhouette Score is 0.004705955274403095\n",
      "For n_clusters=27, The Davies Bouldin Score is 4.465706040885076, The Silhouette Score is 0.0028097364120185375\n",
      "For n_clusters=28, The Davies Bouldin Score is 4.39451618453539, The Silhouette Score is 0.0027551851235330105\n",
      "For n_clusters=29, The Davies Bouldin Score is 4.291719890573037, The Silhouette Score is 0.0018194568110629916\n",
      "For n_clusters=30, The Davies Bouldin Score is 4.2915293312662275, The Silhouette Score is 0.0036382097750902176\n",
      "For n_clusters=31, The Davies Bouldin Score is 4.245837152080447, The Silhouette Score is 0.003815275616943836\n",
      "For n_clusters=32, The Davies Bouldin Score is 4.260234643639513, The Silhouette Score is 0.002618959406390786\n",
      "For n_clusters=33, The Davies Bouldin Score is 4.126062475890035, The Silhouette Score is 0.00432216189801693\n",
      "For n_clusters=34, The Davies Bouldin Score is 4.113719682436045, The Silhouette Score is 0.004637619014829397\n",
      "For n_clusters=35, The Davies Bouldin Score is 4.082649135005471, The Silhouette Score is 0.005141080357134342\n",
      "For n_clusters=36, The Davies Bouldin Score is 4.106511068550381, The Silhouette Score is 0.004329591058194637\n",
      "For n_clusters=37, The Davies Bouldin Score is 4.050942681277461, The Silhouette Score is 0.004626954440027475\n",
      "For n_clusters=38, The Davies Bouldin Score is 4.014070306373826, The Silhouette Score is 0.004559838678687811\n",
      "For n_clusters=39, The Davies Bouldin Score is 4.016532939034867, The Silhouette Score is 0.005545732565224171\n",
      "For n_clusters=40, The Davies Bouldin Score is 4.000136773374545, The Silhouette Score is 0.004688932094722986\n",
      "For n_clusters=41, The Davies Bouldin Score is 3.995342177656985, The Silhouette Score is 0.005956438835710287\n",
      "For n_clusters=42, The Davies Bouldin Score is 3.9723915994869077, The Silhouette Score is 0.005388093180954456\n",
      "For n_clusters=43, The Davies Bouldin Score is 3.9611155199510915, The Silhouette Score is 0.00465589901432395\n",
      "For n_clusters=44, The Davies Bouldin Score is 3.9310650965439917, The Silhouette Score is 0.004610304720699787\n",
      "For n_clusters=45, The Davies Bouldin Score is 3.933002858375443, The Silhouette Score is 0.00408139917999506\n",
      "For n_clusters=46, The Davies Bouldin Score is 3.940052779524737, The Silhouette Score is 0.003880063071846962\n",
      "For n_clusters=47, The Davies Bouldin Score is 3.893619140774507, The Silhouette Score is 0.004104342311620712\n",
      "For n_clusters=48, The Davies Bouldin Score is 3.851852642608512, The Silhouette Score is 0.0036156256683170795\n",
      "For n_clusters=49, The Davies Bouldin Score is 3.805355260192746, The Silhouette Score is 0.0037260418757796288\n",
      "For n_clusters=50, The Davies Bouldin Score is 3.7663024545887804, The Silhouette Score is 0.0054692761041224\n",
      "For n_clusters=51, The Davies Bouldin Score is 3.751521492557723, The Silhouette Score is 0.006089651957154274\n",
      "For n_clusters=52, The Davies Bouldin Score is 3.7523921014106674, The Silhouette Score is 0.0031436544377356768\n",
      "For n_clusters=53, The Davies Bouldin Score is 3.7204908658481735, The Silhouette Score is 0.004308063071221113\n",
      "For n_clusters=54, The Davies Bouldin Score is 3.6970603151148755, The Silhouette Score is 0.0037268579471856356\n",
      "For n_clusters=55, The Davies Bouldin Score is 3.6942244308234207, The Silhouette Score is 0.003365583484992385\n",
      "For n_clusters=56, The Davies Bouldin Score is 3.6717470043929206, The Silhouette Score is 0.0027543024625629187\n",
      "For n_clusters=57, The Davies Bouldin Score is 3.6539491400859325, The Silhouette Score is 0.003101029898971319\n",
      "For n_clusters=58, The Davies Bouldin Score is 3.5805460972885883, The Silhouette Score is 0.004146441351622343\n",
      "For n_clusters=59, The Davies Bouldin Score is 3.5493774470700674, The Silhouette Score is 0.004103898070752621\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "# Convert df_train['Embeddings'] Pandas series to a np.array of float32\n",
    "X = np.array(df_train['Embeddings'].to_list(), dtype=np.float32)\n",
    "\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "for n_cluster in range(2, 60):\n",
    "    kmeans = KMeans(n_clusters=n_cluster, random_state=1).fit(X)\n",
    "    label = kmeans.labels_\n",
    "    db_score = davies_bouldin_score(X, label)\n",
    "    silhouette_score_val = silhouette_score(X, label)\n",
    "    print(\"For n_clusters={}, The Davies Bouldin Score is {}, The Silhouette Score is {}\".format(n_cluster, db_score, silhouette_score_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              repo_name                                     readme_content  \\\n",
      "0           public-apis  # Try Public APIs for free\\nThe Public APIs re...   \n",
      "1  system-design-primer  *[English](README.md) ∙ [日本語](README-ja.md) ∙ ...   \n",
      "2        awesome-python  # Awesome Python [![Awesome](https://cdn.rawgi...   \n",
      "3                Python  <div align=\"center\">\\n<!-- Title: -->\\n  <a hr...   \n",
      "4               AutoGPT  # AutoGPT: Build, Deploy, and Run AI Agents\\n\\...   \n",
      "\n",
      "                                          Embeddings  Cluster_10  \n",
      "0  [0.045818515, -0.04098432, -0.046700705, -0.03...           5  \n",
      "1  [-0.0019060454, -0.028987888, -0.060989663, -0...           7  \n",
      "2  [0.030921018, -0.0451386, -0.043016054, -0.019...           9  \n",
      "3  [0.029836908, -0.019705497, -0.010466749, -0.0...           6  \n",
      "4  [0.042711165, -0.052050836, -0.021455737, -0.0...           7  \n",
      "                 repo_name                                     readme_content  \\\n",
      "17                 whisper  # Whisper\\n\\n[[Blog]](https://openai.com/blog/...   \n",
      "33                   llama  ## **Note of deprecation**\\n\\nThank you for de...   \n",
      "49                  grok-1  # Grok-1\\n\\nThis repository contains JAX examp...   \n",
      "60   text-generation-webui  # Text generation web UI\\n\\nA Gradio web UI fo...   \n",
      "68                    bert  # BERT\\n\\n**\\*\\*\\*\\*\\* New March 11th, 2020: S...   \n",
      "..                     ...                                                ...   \n",
      "970          streaming-llm  # Efficient Streaming Language Models with Att...   \n",
      "974               ipex-llm  > [!IMPORTANT]\\n> ***`bigdl-llm` has now becom...   \n",
      "975  lm-evaluation-harness  # Language Model Evaluation Harness\\n\\n[![DOI]...   \n",
      "994                metaseq  \\n\\n# Metaseq\\nA codebase for working with [Op...   \n",
      "998    Time-Series-Library  # Time Series Library (TSLib)\\nTSLib is an ope...   \n",
      "\n",
      "                                            Embeddings  Cluster_10  \n",
      "17   [-0.016872387, -0.016325865, -0.049222086, 0.0...           0  \n",
      "33   [0.020474967, -0.020240486, 0.0033425607, -0.0...           0  \n",
      "49   [0.045057204, -0.029883139, -0.042422023, -0.0...           0  \n",
      "60   [0.012812026, -0.049691297, -0.046206053, -0.0...           0  \n",
      "68   [-0.022315567, -0.021086266, -0.06000558, 0.00...           0  \n",
      "..                                                 ...         ...  \n",
      "970  [0.019607872, 0.019054497, -0.057948377, 0.041...           0  \n",
      "974  [0.024483424, 0.015938748, -0.044457745, 0.000...           0  \n",
      "975  [0.02827362, -0.01583744, -0.056094557, 0.0062...           0  \n",
      "994  [0.023275888, -0.014419146, -0.06757919, -0.01...           0  \n",
      "998  [0.019370858, -0.021327203, -0.02164608, -0.02...           0  \n",
      "\n",
      "[80 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Perform KMeans clustering with n_clusters = 10\n",
    "kmeans_10 = KMeans(n_clusters=10, random_state=1).fit(X)\n",
    "labels_10 = kmeans_10.labels_\n",
    "\n",
    "# Add the cluster labels to the DataFrame\n",
    "df_train['Cluster_10'] = labels_10\n",
    "    \n",
    "# Display the DataFrame with the new cluster labels\n",
    "print(df_train.head())\n",
    "# Filter the DataFrame to show only the rows belonging to a specific cluster, e.g., cluster 0\n",
    "cluster_0_df = df_train[df_train['Cluster_10'] == 0]\n",
    "\n",
    "# Display the DataFrame for cluster 0\n",
    "print(cluster_0_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_mining",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
