import os
from dotenv import load_dotenv
import streamlit as st
import time
import google.generativeai as genai
load_dotenv()

# Initialize model client 
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
GEMINI_CHAT_MODEL = os.getenv("GEMINI_CHAT_MODEL")
IMG_PATH = os.getenv("IMG_PATH")
# print(f"[*] INFO: gemini api key: {GEMINI_API_KEY}")
# print(f"[*] INFO: gemini model: {GEMINI_CHAT_MODEL}")
# print(f"[*] INFO: image path: {IMG_PATH}")

genai.configure(api_key=GEMINI_API_KEY)
model = genai.GenerativeModel(
            GEMINI_CHAT_MODEL,
            system_instruction="You are a helpful assistant named Github PI who is also a Github expert. Respond like you are a Private Investigator."
        )

# Set Tab title
st.set_page_config(page_title="Github PI", page_icon=":robot_face:")

# Add custom CSS styles
st.markdown(
    """
    <style>
    .sidebar .sidebar-content {
        display: flex;
        flex-direction: column;
        align-items: center;
    }
    </style>
    """,
    unsafe_allow_html=True
)

def reset_chat():
    st.session_state.chat_session = model.start_chat(history=[])

st.title("Github PI")
expander = st.expander("Disclaimer", icon="ℹ️")
expander.write('''
    The information displayed is summary generated by Gemini AI
    trained on Github repository readme files.
    Trust the contents at your own discretion.
''')
octo_img_url = IMG_PATH + '/octocat-1728395775384.png'
with st.sidebar:
    st.markdown("<h1 style='text-align: center;'>!Github Inc.</h1>", unsafe_allow_html=True)
st.sidebar.image(octo_img_url)
st.sidebar.button("Reset Chat", on_click=reset_chat)
st.sidebar.title("About")
st.sidebar.info("Github PI is presented by: Group-11 => Anand, Finn, Georgios & Markus")
      
# Initialize chat history
if "chat_session" not in st.session_state:
    st.session_state.chat_session = model.start_chat(history=[])
    
# Display chat history on rerun
for message in st.session_state.chat_session.history:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])
        
# React to user input
if prompt := st.chat_input("How can I help you today?"):
    with st.chat_message("user"):
        st.markdown(prompt)
    # Add user prompt to chat history
    request = {"role": "user", "content": prompt}
    st.session_state.chat_session.history.append(request)
    
    chat = model.start_chat(history=[])
    stream = chat.send_message(prompt, stream=True)
    # Generate assistant response
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        response = ""
        for chunk in stream:
            for ch in chunk.text.split(' '):
                response += ch + ' '
                time.sleep(0.05)
                message_placeholder.write(response + ' ')
        message_placeholder.write(response)      
    # Add assistant response to chat history
    st.session_state.chat_session.history.append({"role": "assistant", "content": response})
    print(f"[*] INFO: History: {st.session_state.chat_session.history}")

    
